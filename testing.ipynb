{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ner_datasetreference.csv', encoding='latin').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "dataset = df.copy()\n",
    "\n",
    "\n",
    "def _get_word_tokens():\n",
    "        \"\"\"\n",
    "        Private method to generate word tokens.\n",
    "\n",
    "        @return\n",
    "        A tuple of dictionaries, first maps words to integer tokens, \n",
    "        second maps integer tokens to words\n",
    "        \"\"\"\n",
    "\n",
    "        sentences = dataset.groupby(['Sentence #'])['Word'].transform(lambda word : ' '.join(word)).drop_duplicates()\n",
    "\n",
    "        tokenizer = Tokenizer(filters=\"\", lower=True, oov_token='<UNK>', char_level=False)\n",
    "        tokenizer.fit_on_texts(list(sentences))\n",
    "\n",
    "        return tokenizer.word_index\n",
    "\n",
    "\n",
    "def get_tokenized_sentences(max_sentence_len):\n",
    "        \"\"\"\n",
    "        Public method for ...\n",
    "\n",
    "        @return\n",
    "        \"\"\"\n",
    "\n",
    "        word_to_idx          = _get_word_tokens()\n",
    "        word_to_idx['<PAD>'] = 0\n",
    "\n",
    "        temp_dataset               = dataset.copy()\n",
    "        temp_dataset['word_token'] = temp_dataset['Word'].str.lower().map(word_to_idx)           \n",
    "        tokenized_sentences        = temp_dataset.groupby(['Sentence #'])['word_token'].apply(np.array)\n",
    "        padded_tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=max_sentence_len, value=0, padding='post', truncating='post') \n",
    "\n",
    "        return padded_tokenized_sentences, word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_inputs, word_to_idx = get_tokenized_sentences(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word = {idx: word for word, idx in word_to_idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thousands of demonstrators have marched through london to protest the war in iraq and demand the withdrawal of british troops from that country . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"\"\n",
    "\n",
    "for i in sentence_inputs[0]:\n",
    "    string += idx_to_word[i] + \" \"\n",
    "\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 30)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 259,    6,  974,   16, 1791,  237,  467,    7,  522,    2,  129,\n",
       "          5,   61,    9,  575,    2,  832,    6,  185,   90,   22,   15,\n",
       "         56,    3,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "dataset = df.copy()\n",
    "\n",
    "\n",
    "def _get_char_tokens():\n",
    "        \"\"\"\n",
    "        Private method to generate character tokens.\n",
    "\n",
    "        @return\n",
    "        A tuple of dictionaries, first maps chars words to integer tokens, \n",
    "        second maps integer tokens to chars\n",
    "        \"\"\"\n",
    "\n",
    "        words     = dataset['Word'].values\n",
    "\n",
    "        tokenizer = Tokenizer(lower=False, oov_token='<UNK>', char_level=True)\n",
    "        tokenizer.fit_on_texts(list(words))\n",
    "\n",
    "        return tokenizer.word_index\n",
    "\n",
    "\n",
    "\n",
    "def get_tokenized_words(max_word_len):\n",
    "        \"\"\"\n",
    "        Public method for ...\n",
    "\n",
    "        @return\n",
    "        \"\"\"\n",
    "\n",
    "        pad_value = 0\n",
    "\n",
    "        char_to_idx          = _get_char_tokens()\n",
    "        char_to_idx['<PAD>'] = pad_value\n",
    "\n",
    "        temp_dataset                = dataset.copy()\n",
    "        temp_dataset['char_tokens'] = dataset['Word'].str.split(\"\").str[1:-1]\n",
    "        temp_dataset['char_tokens'] = temp_dataset['char_tokens'].apply(lambda x: [char_to_idx[i] for i in x])\n",
    "        tokenized_words             = temp_dataset.groupby(['Sentence #'])['char_tokens'].apply(np.array)\n",
    "\n",
    "\n",
    "        # pop = tokenized_words.reset_index(name= 'char_tokens')['char_tokens']\n",
    "\n",
    "\n",
    "        # padded_tokenized_words = pad_sequences(pop, maxlen=max_word_len, value=0, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "        return tokenized_words, char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop, char_to_idx = get_tokenized_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [27, 10, 7, 14, 8, 3, 6, 12, 8]\n",
       "1                                            [7, 16]\n",
       "2          [12, 2, 15, 7, 6, 8, 4, 9, 3, 4, 7, 9, 8]\n",
       "3                                     [10, 3, 23, 2]\n",
       "4                          [15, 3, 9, 13, 10, 2, 12]\n",
       "                             ...                    \n",
       "1048570                               [4, 10, 2, 19]\n",
       "1048571               [9, 2, 8, 17, 7, 6, 12, 2, 12]\n",
       "1048572                                       [4, 7]\n",
       "1048573                                   [4, 10, 2]\n",
       "1048574                         [3, 4, 4, 3, 13, 25]\n",
       "Name: char_tokens, Length: 1048575, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop['char_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (1,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ABDULR~1\\AppData\\Local\\Temp/ipykernel_7484/2004967126.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m     \u001b[0mpad_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[1;34m(x, ndim, as_index)\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[1;31m# Converting the array with `tolist` seems to improve performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;31m# when iterating and indexing the result (see usage in `pad`)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(array, shape, subok)\u001b[0m\n\u001b[0;32m    178\u001b[0m            [1, 2, 3]])\n\u001b[0;32m    179\u001b[0m     \"\"\"\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[1;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[0;32m    121\u001b[0m                          'negative')\n\u001b[0;32m    122\u001b[0m     \u001b[0mextras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     it = np.nditer(\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multi_index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'refs_ok'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zerosize_ok'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         op_flags=['readonly'], itershape=shape, order='C')\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (1,2)"
     ]
    }
   ],
   "source": [
    "data1=np.pad(pop[:5], ((0, 0), (10,11), (20, 21)), 'constant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>listvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[[27, 10, 7, 14, 8, 3, 6, 12, 8], [7, 16], [12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[[30, 9, 3, 6, 5, 3, 6], [7, 16, 16, 5, 13, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[[41, 2, 11, 5, 13, 7, 17, 4, 2, 9], [18, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[[27, 10, 2, 19], [11, 2, 16, 4], [3, 16, 4, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[[36, 20, 40, 20], [9, 2, 11, 5, 2, 16], [13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>[[50, 17, 17, 7, 8, 5, 4, 5, 7, 6], [11, 2, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>[[50, 6], [27, 10, 14, 9, 8, 12, 3, 19], [24],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>[[45, 7, 11, 11, 7, 21, 5, 6, 18], [30, 9, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>[[26, 5, 6, 13, 2], [4, 10, 2, 6], [24], [3, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>[[27, 10, 2], [36, 6, 5, 4, 2, 12], [40, 3, 4,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #                                         listvalues\n",
       "0          Sentence: 1  [[27, 10, 7, 14, 8, 3, 6, 12, 8], [7, 16], [12...\n",
       "1         Sentence: 10  [[30, 9, 3, 6, 5, 3, 6], [7, 16, 16, 5, 13, 5,...\n",
       "2        Sentence: 100  [[41, 2, 11, 5, 13, 7, 17, 4, 2, 9], [18, 14, ...\n",
       "3       Sentence: 1000  [[27, 10, 2, 19], [11, 2, 16, 4], [3, 16, 4, 2...\n",
       "4      Sentence: 10000  [[36, 20, 40, 20], [9, 2, 11, 5, 2, 16], [13, ...\n",
       "...                ...                                                ...\n",
       "47954   Sentence: 9995  [[50, 17, 17, 7, 8, 5, 4, 5, 7, 6], [11, 2, 3,...\n",
       "47955   Sentence: 9996  [[50, 6], [27, 10, 14, 9, 8, 12, 3, 19], [24],...\n",
       "47956   Sentence: 9997  [[45, 7, 11, 11, 7, 21, 5, 6, 18], [30, 9, 3, ...\n",
       "47957   Sentence: 9998  [[26, 5, 6, 13, 2], [4, 10, 2, 6], [24], [3, 1...\n",
       "47958   Sentence: 9999  [[27, 10, 2], [36, 6, 5, 4, 2, 12], [40, 3, 4,...\n",
       "\n",
       "[47959 rows x 2 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence: 1', 'Sentence: 10', 'Sentence: 100', 'Sentence: 1000',\n",
       "       'Sentence: 10000', 'Sentence: 10001', 'Sentence: 10002',\n",
       "       'Sentence: 10003', 'Sentence: 10004', 'Sentence: 10005',\n",
       "       ...\n",
       "       'Sentence: 9990', 'Sentence: 9991', 'Sentence: 9992', 'Sentence: 9993',\n",
       "       'Sentence: 9994', 'Sentence: 9995', 'Sentence: 9996', 'Sentence: 9997',\n",
       "       'Sentence: 9998', 'Sentence: 9999'],\n",
       "      dtype='object', name='Sentence #', length=47959)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2], [2, 4]]\n",
    "\n",
    "b = pad_sequences(a, maxlen=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db3ca9ec755843094bfe658d337cf97d381b019c52f517307d44cf002f9583d1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
